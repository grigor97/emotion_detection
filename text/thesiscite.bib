@article{google_survey, 
    title={Survey on audiovisual emotion recognition: databases, features, and data fusion strategies}, 
    volume={3}, 
    DOI={10.1017/ATSIP.2014.11}, 
    journal={APSIPA Transactions on Signal and Information Processing}, 
    publisher={Cambridge University Press}, 
    author={Wu, Chung-Hsien and Lin, Jen-Chun and Wei, Wen-Li}, year={2014}, 
    pages={e12}
}

@article{hci_1,
    title = {Emotion recognition in human–computer interaction},
    journal = {Neural Networks},
    volume = {18},
    number = {4},
    pages = {389-405},
    year = {2005},
    issn = {0893-6080},
    doi = {https://doi.org/10.1016/j.neunet.2005.03.006},
    author = {N. Fragopanagos and J.G. Taylor},
}

@article{hci_2,
title = "Emotion Recognition in Human-Computer Interaction",
author = "Roderick Cowie and Ellen Douglas-Cowie and N. Tsapatsoulis and G. Votsis and S. Kollias and W. Fellenz and J. Taylor",
year = "2001",
month = jan,
doi = "10.1109/79.911197",
language = "English",
volume = "18 (1)",
pages = "32--80",
journal = "IEEE Signal Processing Magazine",
issn = "1053-5888",
publisher = "Institute of Electrical and Electronics Engineers Inc.",
number = "1",
}

@article{stanford_2020,
       author = {{Singh}, Mandeep and {Fang}, Yuan},
        title = "{Emotion Recognition in Audio and Video Using Deep Neural Networks}",
      journal = {arXiv e-prints},
         year = 2020,
        month = jun,
          eid = {arXiv:2006.08129},
        pages = {arXiv:2006.08129},
archivePrefix = {arXiv},
       eprint = {2006.08129},
 primaryClass = {eess.AS}
}

@book{af_computing,
author    = "Picard, R.W.",
title     = "Affective Computing",
publisher = "MIT Press",
year      = "1997"
}

@article{china_2020,
       author = {{Zhou}, Hengshun and {Meng}, Debin and {Zhang}, Yuanyuan and {Peng}, Xiaojiang and {Du}, Jun and {Wang}, Kai and {Qiao}, Yu},
        title = "{Exploring Emotion Features and Fusion Strategies for Audio-Video Emotion Recognition}",
      journal = {arXiv e-prints},
         year = 2020,
        month = dec,
          eid = {arXiv:2012.13912},
        pages = {arXiv:2012.13912},
archivePrefix = {arXiv},
       eprint = {2012.13912}
}

@article{india_2020,
       author = {{Nikhil Chennoor}, Sai and {Madhur}, B.~R.~K. and {Ali}, Moujiz and {Kishore Kumar}, T.},
        title = "{Human Emotion Detection from Audio and Video Signals}",
      journal = {arXiv e-prints},
         year = 2020,
        month = jun,
          eid = {arXiv:2006.11871},
        pages = {arXiv:2006.11871},
archivePrefix = {arXiv},
       eprint = {2006.11871}
}

@article{slovenia_2014,
author = {Gajsek, Rok and Štruc, Vitomir and Dobrisek, Simon and Žibert, Janez and Mihelic, France and Pavesic, Nikola},
year = {2009},
month = {09},
pages = {114-121},
journal = {Biometric ID Management and Multimodal },
title = {Combining Audio and Video for Detection of Spontaneous Emotions},
isbn = {978-3-642-04390-1},
doi = {10.1007/978-3-642-04391-8_15}
}

@ARTICLE{waterloo_2019,
       author = {{Sahu}, Gaurav},
        title = "{Multimodal Speech Emotion Recognition and Ambiguity Resolution}",
      journal = {arXiv e-prints},
         year = 2019,
        month = apr,
          eid = {arXiv:1904.06022},
        pages = {arXiv:1904.06022},
archivePrefix = {arXiv},
       eprint = {1904.06022}
}

@article{estonia_2018,
author = {Avots, Egils and Sapiński, Tomasz and Bachmann, Maie and Kamińska, Dorota},
year = {2018},
month = {jul},
pages = {975–985},
journal = {Machine Vision and Applications},
title = {Audiovisual emotion recognition in wild},
doi = {https://doi.org/10.1007/s00138-018-0960-9}
}

@ARTICLE{stuttgart_2021,
       author = {{Neumann}, Michael and {Thang Vu}, Ngoc},
        title = "{Investigations on Audiovisual Emotion Recognition in Noisy Conditions}",
      journal = {arXiv e-prints},
         year = 2021,
        month = mar,
          eid = {arXiv:2103.01894},
        pages = {arXiv:2103.01894},
archivePrefix = {arXiv},
       eprint = {2103.01894}
}


@article{china_2020_1,
AUTHOR = {Ma, Fei and Zhang, Wei and Li, Yang and Huang, Shao-Lun and Zhang, Lin},
TITLE = {Learning Better Representations for Audio-Visual Emotion Recognition with Common Information},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {7239},
URL = {https://www.mdpi.com/2076-3417/10/20/7239},
DOI = {10.3390/app10207239}
}

@article{india_2014,
author = {Gera, Abhishek and Bhattacharya, Arnab},
year = {2014},
month = {03},
pages = {1-10},
journal = {Proceedings of the 1st IKDD Conference on Data Sciences},
title = {Emotion Recognition from Audio and Visual Data using F-score based Fusion},
doi = {10.1145/2567688.2567690}
}

@article{RAVDESS,
    author = {Livingstone, Steven R. AND Russo, Frank A.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English},
    year = {2018},
    month = {05},
    volume = {13},
    url = {https://doi.org/10.1371/journal.pone.0196391},
    pages = {1-35},
    number = {5},
    doi = {10.1371/journal.pone.0196391}
}

@article{savee,
    author = {Philip, Jackson and S Haq},
    journal = {University of Surrey: Guildford, UK},
    
    publisher = {Public Library of Science},
    
    title = {Surrey audio-visual expressed emotion (savee) database},
    year = {2014},
}

@article{iemocap,
author = {Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower Provost, Emily and Kim, Samuel and Chang, Jeannette and Lee, Sungbok and Narayanan, Shrikanth},
year = {2008},
month = {12},
pages = {335-359},
title = {IEMOCAP: Interactive emotional dyadic motion capture database},
volume = {42},
journal = {Language Resources and Evaluation},
doi = {10.1007/s10579-008-9076-6}
}

@article{enterface,
author = {Martin, O. and Kotsia, I. and Macq, Benoit and Pitas, I.},
year = {2006},
month = {02},
pages = {8 - 8},
journal = { Data Engineering Workshops, 2006. Proceedings},
title = {The eNTERFACE'05 Audio-Visual Emotion Database},
doi = {10.1109/ICDEW.2006.145}
}

@article{semanie,
author = {Mckeown, Gary and Valstar, Michel and Cowie, Roddy and Pantic, Maja},
year = {2010},
month = {07},
pages = {1079-1084},
title = {The SEMAINE corpus of emotionally coloured character interactions},
journal = {2010 IEEE International Conference on Multimedia and Expo, ICME 2010},
doi = {10.1109/ICME.2010.5583006}
}

@article{afew,
  author={A. {Dhall} and R. {Goecke} and S. {Lucey} and T. {Gedeon}},
  journal={IEEE MultiMedia}, 
  title={Collecting Large, Richly Annotated Facial-Expression Databases from Movies}, 
  year={2012},
  volume={19},
  number={3},
  pages={34-41},
  doi={10.1109/MMUL.2012.26}
}

@inproceedings{muse_2019,
    title = "{M}u{SE}: a Multimodal Dataset of Stressed Emotion",
    author = "Jaiswal, Mimansa  and
      Bara, Cristian-Paul  and
      Luo, Yuanhang  and
      Burzo, Mihai  and
      Mihalcea, Rada  and
      Provost, Emily Mower",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.187",
    pages = "1499--1510"
}

@inproceedings{feature_fusion1, 
    author = {Schuller, Bj\"{o}rn and Valstar, Michel and Cowie, Roddy and Pantic, Maja}, 
    title = {AVEC 2012: The Continuous Audio/Visual Emotion Challenge - an Introduction}, 
    year = {2012}, 
    isbn = {9781450314671}, 
    publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, 
    url = {https://doi.org/10.1145/2388676.2388758}, 
    doi = {10.1145/2388676.2388758}, booktitle = {Proceedings of the 14th ACM International Conference on Multimodal Interaction}, 
    pages = {361–362}, numpages = {2}
}

@INPROCEEDINGS{feature_fusion2,
  author={A. {Metallinou} and A. {Katsamanis} and M. {Wöllmer} and F. {Eyben} and B. {Schuller} and S. {Narayanan}},
  booktitle={2015 International Conference on Affective Computing and Intelligent Interaction (ACII)}, 
  title={Context-sensitive learning for enhanced audiovisual emotion classification (Extended abstract)}, 
  year={2015},
  volume={},
  number={},
  pages={463-469},
  doi={10.1109/ACII.2015.7344611}}

@inproceedings{feature_fusion3,
title = "Audiovisual vocal outburst classification in noisy conditions",
keywords = "EWI-23055, METIS-296292, IR-84320, HMI-MI: MULTIMODAL INTERACTIONS",
author = "Florian Eyben and Stavros Petridis and Bj{\"o}rn Schuller and Maja Pantic",
note = "10.1109/ICASSP.2012.6289067 ; null ; Conference date: 25-03-2012 Through 30-03-2012",
year = "2012",
month = mar,
day = "25",
doi = "10.1109/ICASSP.2012.6289067",
language = "Undefined",
isbn = "978-1-4673-0045-2",
publisher = "IEEE Computer Society",
pages = "5097--5100",
booktitle = "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2012",
address = "United States",
}